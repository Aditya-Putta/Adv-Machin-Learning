---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  word_document: default
---



# Loading library and IMDB dataset
```{r}
library(keras)
library(tensorflow)
library(tidyverse)

imdb <- dataset_imdb( num_words = 10000)

c(c( train_data, train_lables), c(test_data, test_lables)) %<-% imdb


```

#Encoding the integer sequences into a binary matrix 
```{r}

vectorize_sequence <- function (sequences, dimension = 10000 ) {
  
  results <- matrix (0, nrow = length(sequences), ncol = dimension)
  for ( i in 1: length(sequences))
    results[i, sequences[[i]]] <- 1
           results
}

x_train <- vectorize_sequence(train_data)
x_test <- vectorize_sequence(test_data)
```

#Converting labels to numeric
```{r}
y_train <- as.numeric(train_lables)
y_test <- as.numeric(test_lables)
```

# Setting aside a validation set
```{r}

set.seed(3000)
val_indices <- 1:10000

x_val <- x_train[val_indices,]
partial_x_train <- x_train[-val_indices,]


y_val <- y_train[val_indices]
partial_y_train <- y_train[-val_indices]

```

# Building hypothesis with units =, regularizer_l1(0.001),activateion = "tanh"
```{r}
model <- keras_model_sequential() %>%
  layer_dense(units = 64,kernel_regularizer = regularizer_l1(0.001) ,activation = "tanh", input_shape = c(10000)) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 64,kernel_regularizer = regularizer_l1(0.001), activation = "tanh" ) %>% 
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 64,kernel_regularizer = regularizer_l1(0.001), activation = "tanh" ) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 1, activation = "sigmoid")

```

# Compiling the model
```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss = "mse",
  metrics = c("accuracy")
  )
```

#Training and vaildaitng model
```{r}
history <- model %>% fit(
  partial_x_train,
  partial_y_train,
  epochs = 20,
  batch_size = 250,
  validation_data = list(x_val,y_val)
)

plot(history)
```

# Retraining  and compling the model from scratch and applying it on test data 

```{r}
model_r <- keras_model_sequential() %>%
  layer_dense(units = 64,kernel_regularizer = regularizer_l1(0.001) ,activation = "tanh", input_shape = c(10000)) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 64,kernel_regularizer = regularizer_l1(0.001), activation = "tanh" ) %>% 
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 64,kernel_regularizer = regularizer_l1(0.001), activation = "tanh" ) %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 1, activation = "sigmoid")


model_r %>% compile(
  optimizer = "rmsprop",
  loss = "mse",
  metrics = c("accuracy")
  )

model_r  %>% fit(
  x_train,
  y_train,
  epochs = 6,
  batch_size = 250)

result <- model_r %>%  evaluate(x_test,y_test)

result

```